{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import einops\n",
    "import random\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucf_url = \"./crime_data/UCF_Crimes-Train-Test-Split/Action_Regnition_splits/\"\n",
    "video_url = \"./crime_data/Anomaly-Videos-Part-1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_file = open(f'{ucf_url}ClassIDs.txt',\"r\")\n",
    "classes_ids = classes_file.read().split(\"\\n\")\n",
    "classes = []\n",
    "class_ids = []\n",
    "class_dict = {}\n",
    "for elem in classes_ids:\n",
    "    x = elem.strip().split(' ')\n",
    "    if len(x) == 2:\n",
    "        classes.append(x[0])\n",
    "        class_ids.append(x[1])\n",
    "        class_dict[x[0]] = int(x[1])-1\n",
    "print(classes)\n",
    "print(class_ids)\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_main = open(f'{ucf_url}train_001.txt','r').read().split(' \\n')\n",
    "len(files_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for path in files_main:\n",
    "    if path.split('/')[0] == 'Normal_Videos_event':\n",
    "        l.append(0)\n",
    "    else:\n",
    "        l.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0 : len(l)/(2*l.count(0)), 1 : len(l)/(2*l.count(1))}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_frames(frame, output_size):\n",
    "    frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "    frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "    frane = tf.image.central_crop(frame,0.9)\n",
    "    frame = tf.image.random_crop(value=frame, size=(200,200,3))\n",
    "    return frame\n",
    "\n",
    "def frames_from_video_file(video_path, n_frames, output_size = (240,320)):\n",
    "  video_path = f'{video_url}{video_path}'\n",
    "  result = []\n",
    "  src = cv2.VideoCapture(str(video_path))  \n",
    "  start = 0\n",
    "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
    "  frame_step = int((src.get(cv2.CAP_PROP_FRAME_COUNT) // n_frames) - 1)\n",
    "\n",
    "  ret, frame = src.read()\n",
    "  result.append(format_frames(frame, output_size))\n",
    "\n",
    "  for _ in range(n_frames - 1):\n",
    "    for _ in range(frame_step):\n",
    "      ret, frame = src.read()\n",
    "    if ret:\n",
    "      frame = format_frames(frame, output_size)\n",
    "      result.append(frame)\n",
    "    else:\n",
    "      result.append(np.zeros_like(result[0]))\n",
    "  src.release()\n",
    "  result = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "  return result\n",
    "\n",
    "class FrameGenerator:\n",
    "  def __init__(self, paths, n_frames, class_dictionary, training = False):\n",
    "    self.paths = paths\n",
    "    self.n_frames = n_frames\n",
    "    self.training = training\n",
    "    self.class_ids_for_name = class_dictionary\n",
    "\n",
    "  def get_files_and_class_names(self):\n",
    "    classes = [i.split('/')[0] for i in self.paths] \n",
    "    return self.paths, classes\n",
    "\n",
    "  def __call__(self):\n",
    "    video_paths, classes = self.get_files_and_class_names()\n",
    "\n",
    "    pairs = list(zip(video_paths, classes))\n",
    "\n",
    "    if self.training:\n",
    "      random.shuffle(pairs)\n",
    "\n",
    "    for path, name in pairs:\n",
    "      video_frames = frames_from_video_file(path, self.n_frames)\n",
    "      label = 1\n",
    "      if self.class_ids_for_name[name] == 7:\n",
    "        label = 0\n",
    "      label = to_categorical(label, 2)[0]\n",
    "      yield video_frames, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(files_main)\n",
    "train_set = files_main\n",
    "val_set = [train_set.pop(random.randint(0,len(train_set)-1)) for _ in range(int(len(files_main)*0.20))]\n",
    "print(len(val_set))\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = FrameGenerator(train_set, 30,class_dict, training=True)\n",
    "\n",
    "frames, label = next(fg())\n",
    "\n",
    "print(f\"Shape: {frames.shape}\")\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_signature = (tf.TensorSpec(shape = (30, 200, 200, 3), dtype = tf.float32),\n",
    "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
    "train_ds = tf.data.Dataset.from_generator(FrameGenerator(train_set, 30,class_dict, training=True),\n",
    "                                          output_signature = output_signature)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(FrameGenerator(val_set, 30, class_dict),\n",
    "                                        output_signature = output_signature)\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(500).repeat().prefetch(buffer_size = AUTOTUNE)\n",
    "val_ds = val_ds.cache().shuffle(200).repeat().prefetch(buffer_size = AUTOTUNE)\n",
    "batchsize = 1\n",
    "train_ds = train_ds.batch(batch_size=batchsize)\n",
    "val_ds = val_ds.batch(batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.layers import SpatialDropout3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (None,30,200,200,3)\n",
    "model = keras.Sequential([\n",
    "    layers.Input((input_shape[1:])),\n",
    "    layers.Rescaling(scale=255),\n",
    "    layers.Conv3D(8,(3,3,3), activation=\"relu\",kernel_regularizer=regularizers.L1L2()),\n",
    "    layers.MaxPooling3D(),\n",
    "    layers.SpatialDropout3D(0.2),\n",
    "    layers.Conv3D(16,(3,3,3), activation=\"relu\",kernel_regularizer=regularizers.L1L2()),\n",
    "    layers.MaxPooling3D(),\n",
    "    layers.SpatialDropout3D(0.2),\n",
    "    layers.Conv3D(32,(3,3,3), activation=\"relu\",kernel_regularizer=regularizers.L1L2()),\n",
    "    layers.MaxPooling3D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.BinaryCrossentropy(), \n",
    "              optimizer = keras.optimizers.Adam(), \n",
    "              metrics = ['accuracy','precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.001)\n",
    "earlystopping = EarlyStopping(patience=5,monitor=\"val_accuracy\", restore_best_weights=True)\n",
    "history = model.fit(x = train_ds,\n",
    "                    epochs = 20, \n",
    "                    validation_data = val_ds,\n",
    "                    steps_per_epoch=426 //batchsize,\n",
    "                    validation_steps=106 //batchsize,\n",
    "                    class_weight=class_weights,\n",
    "                    callbacks=[reduce_lr,earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = open(f'{ucf_url}test_001.txt','r').read().split(' \\n')\n",
    "test_ds = tf.data.Dataset.from_generator(FrameGenerator(test_set, 30, class_dict),\n",
    "                                        output_signature = output_signature)\n",
    "test_ds = test_ds.batch(batch_size=batchsize)\n",
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"crime_detection_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
